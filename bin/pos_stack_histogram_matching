#!/usr/bin/python
# -*- coding: utf-8 -*


import os, sys
import copy

from possum import pos_parameters
from possum import pos_wrappers

from possum.pos_wrapper_skel import output_volume_workflow
from possum.pos_itk_core import autodetect_file_type
from possum.pos_common import r


class histogram_matching_multichannel(pos_wrappers.generic_wrapper):
    """
    """

    _template = """c2d -verbose \
        -mcs {first_reference}   -popas iblue -popas igreen -popas ired -clear \
        -mcs {second_reference}  -popas oblue -popas ogreen -popas ored -clear \
        -mcs {section_to_match} -popas mblue -popas mgreen -popas mred -clear \
        -clear \
        -push iblue  -push mblue  -histogram-match {matching_points} -type uchar -popas ablue \
        -push igreen -push mgreen -histogram-match {matching_points} -type uchar -popas agreen \
        -push ired   -push mred   -histogram-match {matching_points} -type uchar -popas ared \
        -clear \
        -push oblue  -push mblue  -histogram-match {matching_points} -type uchar -popas bblue \
        -push ogreen -push mgreen -histogram-match {matching_points} -type uchar -popas bgreen \
        -push ored   -push mred   -histogram-match {matching_points} -type uchar -popas bred \
        -clear \
        -push ablue  -push bblue  -wsum {weight_first} {weight_second} -type uchar -popas wblue \
        -push agreen -push bgreen -wsum {weight_first} {weight_second} -type uchar -popas wgreen \
        -push ared   -push bred   -wsum {weight_first} {weight_second} -type uchar -popas wred \
        -clear \
        -push wred -push wgreen -push wblue \
        -omc 3 {output_filename}"""

    _parameters = {
        'first_reference': pos_parameters.filename_parameter('first_reference', None, str_template="{_value}"),
        'second_reference': pos_parameters.filename_parameter('second_reference', None, str_template="{_value}"),
        'section_to_match': pos_parameters.filename_parameter('section_to_match', None, str_template="{_value}"),
        'matching_points': pos_parameters.value_parameter('matching_points', 32000),
        'weight_first': pos_parameters.value_parameter('weight_first', None),
        'weight_second': pos_parameters.value_parameter('weight_second', None),
        'output_filename': pos_parameters.filename_parameter('output_filename', None, str_template="{_value}")

    }


class histogram_matching_grayscale(pos_wrappers.generic_wrapper):
    """
    """

    _template = """c2d -verbose \
        {first_reference}  -popas first  -clear \
        {second_reference} -popas second -clear \
        {section_to_match} -popas match  -clear \
        -clear \
        -push first  -push match -histogram-match {matching_points} -type uchar -popas amatch \
        -clear \
        -push second -push match -histogram-match {matching_points} -type uchar -popas bmatch \
        -clear \
        -push amatch -push bmatch -wsum {weight_first} {weight_second} -type uchar \
        -o {output_filename}"""

    _parameters = {
        'first_reference': pos_parameters.filename_parameter('first_reference', None, str_template="{_value}"),
        'second_reference': pos_parameters.filename_parameter('second_reference', None, str_template="{_value}"),
        'section_to_match': pos_parameters.filename_parameter('section_to_match', None, str_template="{_value}"),
        'matching_points': pos_parameters.value_parameter('matching_points', 32000),
        'weight_first': pos_parameters.value_parameter('weight_first', None),
        'weight_second': pos_parameters.value_parameter('weight_second', None),
        'output_filename': pos_parameters.filename_parameter('output_filename', None, str_template="{_value}")
    }


class stack_histogram_matching(output_volume_workflow):
    """
    A nice class for unifying illumination and correcting intensity of a stack
    of images (note: not within a single section). The intensity within single
    section has to be already normalized.  The class implements weighted
    histogram matching method and allows for relavively high customization,
    sort of :).
    """

    _f = {
#       'input_stack': pos_parameters.filename('input_stack', work_dir='00_override_this', str_template='{idx:04d}.nii.gz'),
        'input_stack': pos_parameters.filename('input_stack', work_dir='00_override_this', str_template='_error_fname_template_not_set_'),
        'resliced': pos_parameters.filename('resliced', work_dir='09_resliced', str_template='{idx:04d}.nii.gz'),
        'resliced_mask': pos_parameters.filename('resliced_mask', work_dir='09_resliced', str_template='%04d.nii.gz'),
        'out_volume': pos_parameters.filename('out_volume', work_dir='10_output_volumes', str_template='{fname}'),
        }

    __VOL_STACK_SLICE_SPACING = 1

    def _validate_options(self):
        super(self.__class__, self)._validate_options()

        # There have to be some reference sections provided.
        assert self.options.reference_sections is not None, \
            self._logger.error(r("No reference sections provided. \
            Please use `--add-reference-section` to provide reference \
            sections."))

        # There have to be at least two reference sections provided.
        # these two reference section have to be different than the
        # first and the last section of the stack.
        assert len(self.options.reference_sections) >= 2, \
            self._logger.error(r(" There have to be at least four \
            reference sections provided in total including obligatory \
            first and last section of the stack. This is currently not \
            the case. Please provide more reference section \
            using the `--add-reference-section` command line switch."))

        # We need to know where to store the results of the
        # processing.
        assert self.options.output_volume_filename is not None,\
            self._logger.error(r("The output volume filename \
            is required. Please provide the `--output-volume-filename` \
            option and try again."))

#       # We also require that the output volume directory is provided.
#       # (even if it does not cause any error, the default directory
#       # is just a stub)...
#       assert self.options.output_volumes_dir is not None,\
#           self._logger.error(r("The output volume directory \
#           has to be provided. Please supply the \
#           `--output-volumes-dir` option."))

#       # Obviously, the directory with the input images has to be provided as
#       # well
#       assert self.options.input_images_dir is not None,\
#           self._logger.error(r("The directory containing the input \
#           images is required. Please provide the `--input-images-dir` \
#           option."))

        # The input section template is a required parameter because we need
        # to know where to find the sections :)
        assert self.options.input_sections_template is not None, \
            self._logger.error(r("The path to the sections is required. \
            Please provide the `--output-volume-filename` parameters. \
            For now - exiting."))

    def _initializeOptions(self):
        super(self.__class__, self)._initializeOptions()

        # Well, the first thing we would like to check is that
        # ssections range has to be provided. If there are
        # no sections defined, we cannot continue.
        assert self.options.sections_range is not None,\
            self._logger.error(r("Starting and ending slices indexes \
            are not provided. Please supply \
            the first and the last section index."))

        # Define slices' range. All slices within given range will be
        # processed. Make sure that all images are available.
        self._sections = \
            range(self.options.sections_range[0],
                  self.options.sections_range[1] + 1)

        # We need this flag to know if the stack of images, we're currently
        # processing is a multichannel one (=rgb stack) or just a single
        # dimensional one (=grayscale). This flag will be set up as soon as the
        # location of the first image in the stack is determined.
        self._multichannel_workflow = None

    def _overrideDefaults(self):
        super(self.__class__, self)._overrideDefaults()

        # Assing the input sections directory so we know where to look
        # for the sections.
        self.f['input_stack'].override_path = \
            self.options.input_sections_template

        # We override the default output_volumes directory when
        # appropriate command line argument is provided
        self.f['out_volume'].override_dir = self.options.output_volumes_dir

        # Input files have to exist. All of them!
        filenames_to_check = map(lambda x: self.f['input_stack']() % x,
                                self._sections)

        for slice_filename in filenames_to_check:
            self._logger.debug("Checking for image: %s.", slice_filename)

            if not os.path.isfile(slice_filename):
                self._logger.error("File does not exist: %s. Exiting",
                                   slice_filename)
                sys.exit(1)
            else:
                self._logger.debug("Confirmed that file %s exists.",
                                   slice_filename)

    def _generate_section_assignment(self):
        """
        Performs steps related to preprocessing, so everything that is needed
        to do before the actual histogram matching can be applied. Details in
        comments below.

        :return: None
        :rtype: None
        """

        # Below, we'll store the pairs of reference images baed on which we'll
        # interpolate the intensity of the images to normalize. Note that the
        # reference images are not modified during the normalization process.
        # They're histograms remain unchanged.
        self.options.reference_pairs = []

        # The first and the last sections of the stack are added automatically
        # to the list of the reference sections as they are obligatory.
        self.options.reference_sections.append(self._sections[0])
        self.options.reference_sections.append(self._sections[-1])

        # The user can supply the sections of reference intensity in arbitrary
        # order. They have to be sorted before we can do anyting with them.
        # Additionaly, converting the list to set removes any duplicates.
        self.options.reference_sections = \
            sorted(list(set(self.options.reference_sections)))
        ref = self.options.reference_sections

        # Now we can nicely generate tuples of (lower, upper) pairs of
        # sections.
        self.options.reference_pairs = zip(ref[:-1], ref[1:])

        # Print out all the reference images pairs for the purpose of
        # debugging.
        for lower, upper in self.options.reference_pairs:
            self._logger.info(r("Pair of reference images: %d, %d"),\
                              lower, upper)

        self._logger.debug(r("Calculating normalization weights."))
        # Now we calculate a weights for the histogram matching process
        # for each input images and store them in a dictionary.
        self._weights = {}
        for image_index in self._sections:
            self._weights[image_index] = self._calculate_weights(image_index)

        # Print out all the weights, also for the sole purpose of debugging:
        for image_index in sorted(self._weights.keys()):
            (wl, wu), (il, iu) = self._weights[image_index]
            self._logger.info(r("Image %d will be matched with image \
                %d (%f), and image %d (%f)."), image_index, il, wl, iu, wu)

    def _calculate_weights(self, image_index):
        """
        :param image_index: Index of the image for which the normalization
            weight will be calculated.
        :type image_index: int

        :return: Weights and indexes of sections to which given section will be
            normalized. In first tuple the weights are returned and in the second,
            the sections indexes are returned.
        :rtype: ((float, float), (int, int))
        """

        # Determine, to which interval given slice belongs to
        span = self._get_interval(image_index)

        # Ok. Some explanation here. The user can sypply any wired
        # configuration of the reference sections. For instance few reference
        # sections in a row. Or better, refernce secion which is exclyded from
        # processing. This may lead to a situation when the diff is 0. This
        # needs to be handled separaterly.
        diff = span[1] - span[0]
        if span != 0:
            w1 = float(span[1] - image_index) / float(diff)
            w2 = float(1 - w1)
        else:
            w1, w2 = (1.0, 0.0)

        return ((w1, w2), span)

    def _get_interval(self, image_index):
        """
        """

        for lower, upper in self.options.reference_pairs:
            if image_index >= lower and image_index <= upper:
                return lower, upper

        # Sometimes it might happen (and this is an unwanted situation)
        # that the set of reference sections does not cover particular
        # section to be normalized. In such situation we check if the section
        # to be normalized has not been actually excluded from normalization
        # by using the '--exclude-section' switch.
        # If that's not the case, we unfortunately cannot continue as every
        # section has to have a reference span assigned. This, quite demanding,
        # condition might be changed in the future, but for now let it be.
        self._logger.debug(r("No reference sections detected for %d section. \
            Checking if the section has been excluded from processing."),
            image_index)

        if image_index not in self.options.excluded_sections:
            self._logger.error(r("Section %d has not been excluded from \
            processing but has no reference sections assigned. \
            That's clearly an error. Cannot continue."), image_index)
            sys.exit(1)
        else:
            self._logger.info(r("Section %d has been excluded from \
            processing and it will be normalized to itself. The \
            resulting image should be identical to the inputed image"), \
            image_index)

            # The trick is that instead of copying the file (which would be
            # probably the most reasonable thing to do but at the same time
            # would make the architecture of the script less streamlined) we
            # ask the script to normalize the image to itself. This translate
            # to matching given section histogram with itself so no change
            # should be applied. Again, copying the input file would be much,
            # much better. If you're reading this commment, you should propably
            # just implement this feature here.

            return image_index, image_index

    def launch(self):
        # A preprocessing step.
        self._generate_section_assignment()

        # Get the pixel type so we'll know what kind of workflow to apply.
        pixel_type = self._autodetect_workflow_type()

        if pixel_type in ["vector", "rgb"]:
            self._logger.info(r("Reslicing the images using \
                    the multichannel workflow."))
            self._multichannel_workflow = True
        else:
            self._logger.info(r("Reslicing the images using the \
                    grayscale reslice workflow."))
            self._multichannel_workflow = False

        # Do the actual matching.
        self._histogram_match_stack()

        # And stack the normalized images back into a volume.
        self._stack_resliced_sections()

    def _autodetect_workflow_type(self):
        """
        Determine the image type and use proper reslicing routine depending
        on the image type (either grayscale reslicing process or the rgb
        image reslicing process). To determine the image type, the first
        image in the stack is read and the component type is determined. If
        the image is a multicomponent, a multicomponent reslicing workflow is
        used.

        :return: Pixel type of the image used to determine the type of the
        worklfow. This will be either 'rgb', 'vector' or 'scalar'.
        :rtype: str
        """

        self._logger.debug(r("Detecting the image properties of the\
            first image in the stack to choose a proper \
            reslicing routine."))

        first_img_idx = self._sections[0]
        first_img_fname = self.f['input_stack']() % first_img_idx
        pixel_type = autodetect_file_type(first_img_fname, ret_itk=False)[0]

        self._logger.debug(r("%s pixel type detected. Returning \
                             the value."), pixel_type)

        return pixel_type

    def _get_histogram_matching_wrapper(self, image_index):
        """
        :param image_index: Index of the image for which the histogram matching
            command will be generated.
        :type image_index: int

        :return: Wrapper for processing particular image
        :rtype: :class:`pos_wrappers.generic_wrapper`
        """

        # There are two types of wrappers depending on the image type.
        # One for scalar images and one for multicomponent (well... rgb)
        # images. Pick the right one,
        wrapper_types = {True: histogram_matching_multichannel,
                        False: histogram_matching_grayscale}

        # Pick the right one
        histogram_matching_wrapper = \
            wrapper_types[self._multichannel_workflow]

        # Upnack the images indexes and the images weights to
        # build the command to be executed.
        (lower_weight, upper_weight), (lower_section, upper_section) = \
            self._weights[image_index]

        # Generate the command line command...
        command = histogram_matching_wrapper(
            first_reference=self.f['input_stack']() % lower_section,
            second_reference=self.f['input_stack']() % upper_section,
            section_to_match=self.f['input_stack']() % image_index,
            matching_points=self.options.histogram_matching_points,
            weight_first=lower_weight,
            weight_second=upper_weight,
            output_filename=self.f['resliced'](idx=image_index))

        # And then return the wrapper (actually, its copy :)
        return copy.deepcopy(command)

    def _histogram_match_stack(self):
        """
        Conduct the actual image processing.

        :return: None
        :rtype: None
        """

        # Commands to execute will be collected here.
        commands = []

        for image_index in self._sections:
            command = self._get_histogram_matching_wrapper(image_index)
            commands.append(copy.deepcopy(command))

        # Execute the whole batch.
        self.execute(commands)

    def _stack_resliced_sections(self):
        """
        Merge registered and resliced images into consitent volume with
        assigned voxel spacing. Grayscale as well as multichannel volumes could
        be processed therefore we do not need two separate functions.

        :return: None
        :rtype: None
        """

        filename = self.options.output_volume_filename

        # Not much of a philosophy, just take the images and stack them.
        # this piece of code repeats in many scripts.

        output_filename = self.f['out_volume'](fname=filename)
        command = self._get_generic_stack_slice_wrapper(
            self.f['resliced_mask'](),
            output_filename)
        self.execute(command)

    def _get_generic_stack_slice_wrapper(self, mask_type, output_filename):
        """

        Return generic command wrapper suitable either for stacking grayscale
        images or multichannel images. Aproperiate command line wrapper
        is returned depending on provided `mask_type` and
        `output_filename type`. The command line wrapper is prepared mostly
        based on the command line parameters which are common between both
        images stacks thus so there is no need to parametrize them
        individually.

        :param mask_type: mask type determining which images stack will be
                          converted into a volume.
        :type mask_type: str

        :param output_filename: output filename itself :)
        :type output_filename: str
        """

        # Assign some usefull aliases. The processing regards only slices that
        # are withing the moving slices index.
        start = self._sections[0]
        stop = self._sections[-1]

        # Define the warpper according to the provided settings.
        command = pos_wrappers.stack_and_reorient_wrapper(
            stack_mask=mask_type,
            slice_start=start,
            slice_end=stop,
            slice_step=self.__VOL_STACK_SLICE_SPACING,
            output_volume_fn=output_filename,
            permutation_order=self.options.output_volume_permute_axes,
            orientation_code=self.options.output_volume_orientation,
            output_type=self.options.output_volume_scalar_type,
            spacing=self.options.output_volume_spacing,
            origin=self.options.output_volume_origin,
            interpolation=self.options.output_volume_interpolation,
            resample=self.options.output_volume_resample)

        # Return the created wrapper.
        return copy.deepcopy(command)

    @classmethod
    def _getCommandLineParser(cls):
        parser = output_volume_workflow._getCommandLineParser()

        # TODO: Implement excluding the sections as this has not been
        # TODO: Implement the input section filename template
        # so not only nifti files could be used but also different file
        # formats e.g. png
        # implemented yet.

        parser.add_option('--sections-range', default=None, nargs=2, type='int',
            dest='sections_range',
            help='Index of the first slice of the stack')
        parser.add_option('--add-reference-section', default=None,
            dest='reference_sections', action='append', nargs=1, type='int',
            help=r('Add a reference section. There has to be at least four \
            reference section for the workflow to proceed. The first section \
            of the stack and the last section of the stack are required \
            therefore they are added automatically. \
            this leaves used to add two reference sections at minumum.\
            Duplicates are removed from the list.'))
        parser.add_option('--exclude-section', default=None,
            dest='excluded_sections', action='append', nargs=1, type='int',
            help=r('Exclude given section from processing.\
            This means that section with given index will not be processed \
            and will be left as it came.'))
        parser.add_option('--histogram-matching-points', default=2048,
            dest='histogram_matching_points', action='store', type='int',
            help=r('Number of points used in the histogram matchcing \
            algorithm. Please refer to the ITK documentation for details.\
            Default value is 2048 which is quite high.'))
        parser.add_option('--output-volumes-dir', default=None,
            type='str', dest='output_volumes_dir', help=r('...'))
        parser.add_option('--output-volume-filename', default=None,
            type='str', dest='output_volume_filename', help=r('...'))
        # TODO: Merge the output volumes directory and the output volume
        # filename into a single command line parameter.

        parser.add_option('--input-sections-template', default=None,
            type='str', dest='input_sections_template', help=r('Filename \
            template for the input sections. This is a required parameter \
            and the workflow will not run without it. Provide a full path \
            and the section filename template there. For instance \
            /some/path/to/a/dir/section_\%04d.nii.gz .'))

        return parser

if __name__ == '__main__':
    options, args = stack_histogram_matching.parseArgs()
    workflow = stack_histogram_matching(options, args)
    workflow.launch()
